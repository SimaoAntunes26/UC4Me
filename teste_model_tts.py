import speech_recognition as sr
from pynput import keyboard
import threading
import time
import cv2
import torch
import numpy as np
import sys
import pyaudio
import edge_tts
import asyncio
import pygame
import io

class IntegratedVoiceAssistant:
    def __init__(self):
        self.recognizer = sr.Recognizer()
        self.is_recording = False
        self.audio_data = None
        self.recording_thread = None
        
        # YOLO model
        self.yolo_model = None
        
        # Keyboard listener
        self.listener = None
        
        # PyAudio settings
        self.chunk = 1024
        self.format = pyaudio.paInt16
        self.channels = 1
        self.rate = 44100
        
        # Edge TTS settings for European Portuguese
        self.voice = "pt-PT-RaquelNeural"  # European Portuguese female voice
        
        # Initialize pygame for audio playback
        pygame.mixer.init()
        
        # Mode selection variables
        self.waiting_for_mode_selection = True
        self.current_mode = None
        
        print("ü§ñ Integrated Voice Assistant with Object Detection initialized!")

    def load_yolo_model(self):
        """Load YOLOv5 nano model"""
        try:
            print("üì¶ Loading YOLOv5 model...")
            self.speak("A carregar o modelo de dete√ß√£o de objetos...")
            
            model = torch.hub.load('ultralytics/yolov5', 'yolov5n', pretrained=True)
            model.eval()
            self.yolo_model = model
            
            print("‚úÖ YOLOv5 model loaded successfully!")
            self.speak("Modelo carregado com sucesso!")
            return True
        except Exception as e:
            print(f"‚ùå Error loading YOLOv5 model: {e}")
            self.speak("Erro ao carregar o modelo de dete√ß√£o de objetos.")
            return False

    def speak(self, text):
        """Convert text to speech using Edge TTS"""
        async def _speak():
            try:
                communicate = edge_tts.Communicate(text, self.voice)
                
                # Create audio data in memory
                audio_data = io.BytesIO()
                async for chunk in communicate.stream():
                    if chunk["type"] == "audio":
                        audio_data.write(chunk["data"])
                
                # Reset position to beginning
                audio_data.seek(0)
                
                # Play audio using pygame
                pygame.mixer.music.load(audio_data)
                pygame.mixer.music.play()
                
                # Wait for playback to finish
                while pygame.mixer.music.get_busy():
                    time.sleep(0.1)
            except Exception as e:
                print(f"TTS Error: {e}")
        
        # Run the async function
        try:
            asyncio.run(_speak())
        except Exception as e:
            print(f"Speech synthesis error: {e}")

    def take_photo_and_detect(self):
        """Take a photo using OpenCV and run YOLOv5 object detection with voice output"""
        try:
            print("üì∏ Taking photo...")
            self.speak("A tirar fotografia...")
            
            # Initialize camera
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                print("‚ùå Error: Could not open camera")
                self.speak("Erro: n√£o consegui aceder √† c√¢mara.")
                return
            
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                print("‚ùå Error: Could not capture image")
                self.speak("Erro: n√£o consegui capturar a imagem.")
                return
            
            # Save the captured image
            cv2.imwrite('captured_image.jpg', frame)
            print("‚úÖ Photo captured!")
            self.speak("Fotografia capturada!")
            
            # Run inference
            print("üîç Running object detection...")
            self.speak("A analisar objetos na imagem...")
            results = self.yolo_model(frame)
            
            # Extract detected objects
            detections = results.pandas().xyxy[0]
            
            if len(detections) > 0:
                print(f"\nüéØ Detected {len(detections)} objects:")
                objects = []
                for _, detection in detections.iterrows():
                    obj_name = detection['name']
                    confidence = detection['confidence']
                    objects.append(f"{obj_name} com {confidence:.0%} de confian√ßa")
                    print(f"- {obj_name} ({confidence:.2f})")
                
                # Speak the detected objects
                objects_text = f"Detetei {len(detections)} objetos: " + ", ".join(objects)
                self.speak(objects_text)
            else:
                print("‚ùå No objects detected")
                self.speak("N√£o detetei nenhum objeto na imagem.")
                
        except Exception as e:
            print(f"‚ùå Error in photo capture/detection: {e}")
            self.speak("Erro durante a captura ou an√°lise da imagem.")

    def count_g_presses_for_detection(self):
        """Count G key presses for 5 seconds and perform actions based on count"""
        g_count = 0
        running = True
        listener = None
        
        def on_press(key):
            nonlocal g_count
            if running:
                try:
                    if key.char and key.char.lower() == 'g':
                        g_count += 1
                        print(f"G pressed! Count: {g_count}")
                except AttributeError:
                    # Special keys don't have char attribute
                    pass
        
        def stop_counting():
            nonlocal running, listener
            time.sleep(5)
            running = False
            if listener:
                listener.stop()
        
        print("\n" + "="*50)
        print("üéÆ Press the G key as many times as you want!")
        print("‚è∞ You have 5 seconds starting... NOW!")
        self.speak("Prima a tecla G quantas vezes quiser. Tem 5 segundos a partir de... agora!")
        
        # Set up the key listener
        listener = keyboard.Listener(on_press=on_press)
        listener.start()
        
        # Start the timer thread
        timer_thread = threading.Thread(target=stop_counting)
        timer_thread.start()
        
        # Wait for the timer to finish
        timer_thread.join()
        
        print(f"\n‚è∞ Time's up! You pressed the G key {g_count} times in 5 seconds.")
        self.speak(f"Tempo esgotado! Primiu a tecla G {g_count} vezes em 5 segundos.")
        
        # Process based on number of presses
        if g_count == 1:
            print("üì∏ Taking photo and detecting objects...")
            self.speak("A tirar fotografia e detetar objetos...")
            self.take_photo_and_detect()
        elif 2 <= g_count <= 4:
            message = f"Prima a tecla G {g_count} vezes - apenas a contar"
            print(f"üî¢ G key pressed {g_count} times - just counting")
            self.speak(message)
        elif g_count > 4:
            print("‚ùå Invalid input! Too many presses (more than 4)")
            self.speak("Entrada inv√°lida! Demasiadas press√µes, mais de 4.")
        else:
            print("‚ùå No G key presses detected")
            self.speak("N√£o detetei press√µes na tecla G.")

    def on_key_press_mode_selection(self, key):
        """Handle key press for mode selection"""
        try:
            if hasattr(key, 'char') and key.char and key.char.lower() == 'g':
                if self.waiting_for_mode_selection:
                    self.select_mode()
                elif self.current_mode == "detection":
                    # Start the G-key counting for object detection
                    self.count_g_presses_for_detection()
                elif self.current_mode == "voice":
                    # Start 5-second voice recording
                    self.handle_g_press_voice()
        except AttributeError:
            pass

    def on_key_release(self, key):
        """Handle key release events"""
        # Check for Ctrl+C to exit
        if key == keyboard.Key.ctrl_l or key == keyboard.Key.ctrl_r:
            return False

    def select_mode(self):
        """Let user select between detection mode and voice assistant mode"""
        self.waiting_for_mode_selection = False
        
        print("\nüéØ Mode Selection:")
        print("1Ô∏è‚É£  Press G ONCE for Object Detection Mode")
        print("2Ô∏è‚É£  Press G TWICE for Voice Assistant Mode")
        print("‚è∞ You have 3 seconds to choose...")
        
        self.speak("Sele√ß√£o de modo: Prima G uma vez para dete√ß√£o de objetos, ou duas vezes para assistente de voz. Tem 3 segundos para escolher.")
        
        # Count G presses for mode selection
        g_count = 0
        running = True
        
        def count_presses(key):
            nonlocal g_count
            if running:
                try:
                    if key.char and key.char.lower() == 'g':
                        g_count += 1
                        print(f"Mode selection G press: {g_count}")
                except AttributeError:
                    pass
        
        # Set up temporary listener for mode selection
        temp_listener = keyboard.Listener(on_press=count_presses)
        temp_listener.start()
        
        # Wait 3 seconds
        time.sleep(3)
        running = False
        temp_listener.stop()
        
        # Determine mode based on G presses
        if g_count == 1:
            self.current_mode = "detection"
            print("üéØ Object Detection Mode selected!")
            self.speak("Modo de dete√ß√£o de objetos selecionado!")
            print("\nüìã Instructions for Object Detection Mode:")
            print("- Press G once: Take photo and detect objects")
            print("- Press G 2-4 times: Just count the presses")
            print("- Press G more than 4 times: Invalid input")
            self.speak("Instru√ß√µes: Prima G uma vez para fotografar e detetar objetos, 2 a 4 vezes apenas para contar, mais de 4 vezes √© entrada inv√°lida.")
        elif g_count == 2:
            self.current_mode = "voice"
            print("üé§ Voice Assistant Mode selected!")
            self.speak("Modo assistente de voz selecionado!")
            print("\nüìã Instructions for Voice Assistant Mode:")
            print("- Press G to start 5-second voice recording")
            print("- Speak your command during the recording")
            self.speak("Prima G para iniciar grava√ß√£o de 5 segundos e dar comandos de voz.")
        else:
            print("‚ùå No valid mode selected, defaulting to Object Detection Mode")
            self.speak("Nenhum modo v√°lido selecionado, a usar modo de dete√ß√£o de objetos por defeito.")
            self.current_mode = "detection"

    def handle_g_press_voice(self):
        """Handle G key press for voice mode - start 5-second recording"""
        if self.is_recording:
            print("‚ö†Ô∏è Already recording, please wait...")
            self.speak("J√° estou a gravar, por favor aguarde.")
            return
        
        print("üî¥ Starting 5-second recording...")
        self.speak("A iniciar grava√ß√£o de 5 segundos.")
        self._start_5_second_recording()

    def _start_5_second_recording(self):
        """Start recording for exactly 5 seconds"""
        self.is_recording = True
        self.recording_thread = threading.Thread(target=self._record_for_5_seconds)
        self.recording_thread.start()

    def _record_for_5_seconds(self):
        """Record audio for exactly 5 seconds using PyAudio"""
        try:
            audio = pyaudio.PyAudio()
            
            stream = audio.open(
                format=self.format,
                channels=self.channels,
                rate=self.rate,
                input=True,
                frames_per_buffer=self.chunk
            )
            
            frames = []
            
            # Record for exactly 5 seconds
            start_time = time.time()
            recording_duration = 5.0
            
            print("üî¥ Recording... ", end="", flush=True)
            
            while time.time() - start_time < recording_duration:
                data = stream.read(self.chunk)
                frames.append(data)
                
                # Show countdown
                elapsed = time.time() - start_time
                remaining = recording_duration - elapsed
                if int(remaining) != int(remaining + 0.1):
                    print(f"{int(remaining + 1)}... ", end="", flush=True)
            
            print("‚èπÔ∏è")
            
            stream.stop_stream()
            stream.close()
            audio.terminate()
            
            # Convert to speech_recognition AudioData format
            audio_data = b''.join(frames)
            self.audio_data = sr.AudioData(audio_data, self.rate, 2)
            
            self.is_recording = False
            print("‚úÖ Recording completed! Processing...")
            self.speak("Grava√ß√£o completa! A processar...")
            self._process_audio()
            
        except Exception as e:
            print(f"‚ùå Recording error: {e}")
            self.speak("Erro durante a grava√ß√£o.")
            self.is_recording = False

    def _process_audio(self):
        """Process the recorded audio"""
        if self.audio_data is None:
            print("‚ùå No audio data to process.")
            return

        try:
            print("üîÑ Converting speech to text...")
            self.speak("A converter voz para texto...")
            
            # Convert speech to text using European Portuguese
            text = self.recognizer.recognize_google(self.audio_data, language='pt-PT')
            print(f"üìù You said: '{text}'")
            
            # Play back what was said
            self.speak(f"Disseste: {text}")
            
            # Process the command
            result = self._handle_voice_command(text.lower())
            if result == "exit":
                return "exit"
            
        except sr.UnknownValueError:
            print("‚ùå Sorry, I couldn't understand the audio.")
            self.speak("Desculpa, n√£o consegui perceber o que disseste.")
        except sr.RequestError as e:
            print(f"‚ùå Speech recognition service error: {e}")
            self.speak("Desculpa, houve um erro com o servi√ßo de reconhecimento de voz.")
        except Exception as e:
            print(f"‚ùå Unexpected error: {e}")
            self.speak("Desculpa, ocorreu um erro inesperado.")
        
        # Reset audio data
        self.audio_data = None
        print("\n‚è≥ Ready for next command. Press 'G' to record again...")

    def _handle_voice_command(self, command):
        """Handle voice commands"""
        if any(word in command for word in ["sair", "parar", "terminar", "adeus", "tchau"]):
            self.speak("Adeus!")
            return "exit"
        elif any(word in command for word in ["foto", "fotografia", "imagem", "c√¢mara", "camera"]):
            self.speak("A tirar fotografia e detetar objetos...")
            self.take_photo_and_detect()
        elif any(word in command for word in ["teu nome", "quem √©s", "nome", "quem es"]):
            self.speak("Sou o teu assistente integrado com dete√ß√£o de objetos.")
        elif any(word in command for word in ["horas", "tempo", "que horas"]):
            from datetime import datetime
            current_time = datetime.now().strftime("%H:%M")
            self.speak(f"S√£o {current_time}")
        elif any(word in command for word in ["ol√°", "oi", "bom dia", "ola"]):
            self.speak("Ol√°! Como posso ajudar?")
        elif any(word in command for word in ["obrigado", "obrigada"]):
            self.speak("De nada! Fico feliz em ajudar.")
        elif any(word in command for word in ["como est√°s", "como estas", "tudo bem"]):
            self.speak("Estou bem, obrigado! E tu?")
        else:
            self.speak("Ouvi-te, mas ainda estou a aprender a responder a esse comando.")

    def start_keyboard_listener(self):
        """Start the keyboard listener"""
        self.listener = keyboard.Listener(
            on_press=self.on_key_press_mode_selection,
            on_release=self.on_key_release
        )
        self.listener.start()
        return self.listener

    def run(self):
        """Main run method"""
        try:
            # Load YOLO model first
            if not self.load_yolo_model():
                print("‚ùå Failed to load YOLO model. Exiting...")
                return
            
            # Start keyboard listener
            listener = self.start_keyboard_listener()
            
            print("\nüöÄ Sistema integrado pronto!")
            self.speak("Sistema integrado pronto! Prima G para selecionar o modo.")
            
            print("\n‚è≥ Press 'G' to select mode...")
            print("   - Press Ctrl+C to exit anytime")
            
            # Keep the main thread alive
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                print("\n\nüëã Exiting integrated assistant...")
                self.speak("A sair do assistente integrado. Adeus!")
                if self.is_recording:
                    self.is_recording = False
                listener.stop()
                
        except Exception as e:
            print(f"\n‚ùå Fatal error: {e}")
            self.speak("Erro fatal do sistema.")

def main():
    print("\nü§ñ Integrated Voice Assistant with Object Detection")
    print("=" * 60)
    print("üéØ Features:")
    print("  ‚Ä¢ Object Detection Mode: Press G keys to take photos and detect objects")
    print("  ‚Ä¢ Voice Assistant Mode: Press G to record voice commands")
    print("  ‚Ä¢ European Portuguese TTS and Speech Recognition")
    print("  ‚Ä¢ YOLOv5 Object Detection with voice feedback")
    print("\nüöÄ Starting system...")
    print("‚ö†Ô∏è  Make sure your camera and microphone are connected!")
    print("‚ö†Ô∏è  For SSH users: Use 'ssh -X' for X11 forwarding")
    
    try:
        assistant = IntegratedVoiceAssistant()
        assistant.run()
        
    except Exception as e:
        print(f"\n‚ùå Fatal error: {e}")
        print("üí° Required libraries:")
        print("   pip install pynput opencv-python torch torchvision")
        print("   pip install SpeechRecognition pyaudio edge-tts pygame")

if __name__ == "__main__":
    main()